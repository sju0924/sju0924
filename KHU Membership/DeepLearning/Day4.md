## 객체 감지

## yolo Network
> 1. 입력 이미지 크기 조정
> 2. 이미지에 대해 단일 컨볼루션 네트워크를 실행
> 3. 모델의 confidence에 의한 결과 탐지

> 패턴을 모은 것에 대해서는 넓게 보겠다?
> 눈. 점 등 추상화될 수 있는 객체가 중요하게 생각된다?

## FCN vs CNN
> 1. 밀집 층은 특정 입력 크기를 기대하지만 합성곱 층은 어떤 크기의 이미지도 처리할 수 있음
> 2. CNN을 FCN 으로. 가중치 복사도 가능.
> 3. 224x224  이미지에서 트레이닝. 10개 숫자를 출력?<br>
>* 0~4: 소프트맥스 활성화 함수 통과. 클래스 확률
>* 5: 로지스틱 통과
>* 6~9: 

## 모델
>* 시스템은 탐지를 회귀 문제로 모델링
>* 이미지를 SxS 그리드로 나눔
>   >* 각 그리드 셀에 대해 B 경계 상자. 해당 상자에 대한 신뢰도
>   >* C 클래스 확률을 예측
>* 이러한 예측은 SxSx(B*5+C) 텐서로 인코딩

## YOLO
>* 탐지 네트워크는 24개 컨볼루션 레이어와 2개 완전 연결 레이어
>* 1x1 컨볼루션 레이어를 번갈아 사용하면 이전 레이어의 특징 공간이 줄어듦.
>* 절반 해상도의 ImageNet 분류에 대해 사전 트레이닝된 컨벌루션 레이어를 사용
>* 감지를 위해 해상도를 두 배로 늘린다.

## Non-max suppression
### 간단한 객체 탐지. 일종의 후처리?
> 각 바운딩 박스에 대해 객체 존재여부 확률?
> 존재 여부가 임곗값 이하인 박스 삭제
> 가장 높은 점수를 가진 것 찾고 그다음 높은거랑 비교
> IoU(?) 비교하고 이게 지정한 점수 이상이면 제거

## Loss
좀 복잡함<br>
개어려워!!!!!!!!!!!!!!!!!!!<br>
confidence?

## Semantic Segmentation 활용한 차량 파손 탐지 모델 개발기
> 딥러닝 모델 Serving 간단 구축기
>tech.socarcorp.kr/data/2020/03/10/ml-model-serving.html

## Project 소개
> koslab 사이트에 있음.<br>

## 전이 학습
>backbone?<br>
>https://keras.io/examples/vision/image_classification_with_vision_transformer/



