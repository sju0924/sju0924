# Day 1
## 퍼셉트론
 입력을 주면 가중치에 따라 출력이 나옴
## 다층 퍼셉트론
## 경사 하강법
>* 한 번에 하나의 미니배치씩 진행하여 전체 훈련 세트 처리. 이를 여러번 반복함. 한 반복을 에포크라고 한다.
>* 처음 은닉 층에서 뉴런 출력 계산하고 다음층 전달. 마지막 출력층 계산할때까지 하는게 정방향 계산.
>* 역방향 계산 위해 중간 계산값 모두 저장.
>* 알고리즘이 네트워크의 출력 오차 측정

## 케라스, 텐서플로
>* 케라스가 API 형식으로 딥러닝의 여러 라이브러리를 묶어서 제공. pytorch 백엔드는 제공하지 않는다.
>* 텐서플로2부터는 케라스를 공식 API로 채택


## MNIST
>* Fashion MNIST: 라벨을 단일 숫자로 해서 28x28 크기의 그레이스케일 이미지를 분류

## Categorical Crossentropy

>* 카테고리별 확률의 차이
>* 타겟에 출력 결과의 자연 로그를 곱한 후 다 더하여 음수로 변환

## 데이터 분리
>* 검증 데이터로 훈련의 중지 지점 지정해 과대적합 방지

## 네트워크 구조
>* 활성화 함수: 비선형성 추가. ReLu가 빠름.
>* Softmax: 0~1의 범위로 만듦.
>* 초기화

## Logit
>* 확률화 되지 않은 예측 결과

